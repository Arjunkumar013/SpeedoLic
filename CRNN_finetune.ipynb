{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioqoasUqbcTi",
        "outputId": "7d7996cc-74dd-4b42-ec1d-3c7dfaddbdf3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "\n"
      ],
      "metadata": {
        "id": "D2WbUqk9hmHa"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ALPHABET = \"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
        "char2idx = {c: i+1 for i, c in enumerate(ALPHABET)}  # 0 reserved for blank\n",
        "idx2char = {i+1: c for i, c in enumerate(ALPHABET)}\n"
      ],
      "metadata": {
        "id": "TLX6b2VYhmJ9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class OCRDataset(Dataset):\n",
        "    def __init__(self, root):\n",
        "        self.img_dir = os.path.join(root, \"images\")\n",
        "        self.labels = []\n",
        "\n",
        "        with open(os.path.join(root, \"labels.txt\")) as f:\n",
        "            for line in f:\n",
        "                name, text = line.strip().split(\"\\t\")\n",
        "                self.labels.append((name, text))\n",
        "\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.ToPILImage(),\n",
        "            transforms.Resize((32, 100)),\n",
        "            transforms.Grayscale(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5,), (0.5,))\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        name, text = self.labels[idx]\n",
        "        img = cv2.imread(os.path.join(self.img_dir, name))\n",
        "        img = self.transform(img)\n",
        "\n",
        "        target = torch.tensor([char2idx[c] for c in text], dtype=torch.long)\n",
        "        return img, target, len(target)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "dataset = OCRDataset(\"/content/drive/MyDrive/ANPR_OCR_Dataset\")\n",
        "\n",
        "loader = DataLoader(\n",
        "    dataset,\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    collate_fn=collate_fn\n",
        ")\n",
        "\n",
        "print(\"Dataset size:\", len(dataset))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YyRTj1GohmMo",
        "outputId": "f6df5926-ae61-4cab-8bc4-6e5b804766a2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset size: 1337\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch):\n",
        "    imgs, targets, lengths = zip(*batch)\n",
        "    imgs = torch.stack(imgs)\n",
        "    targets = torch.cat(targets)\n",
        "    lengths = torch.tensor(lengths)\n",
        "    return imgs, targets, lengths\n"
      ],
      "metadata": {
        "id": "2mlIMQQwhmOy"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CqOdfGw-OBfd",
        "outputId": "126a3ada-c5f2-4166-abf4-3949202f6f11"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/JaidedAI/EasyOCR.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqVkJ8EYOwKo",
        "outputId": "ef01624b-0e3a-42b0-fe1c-49562a910b7f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'EasyOCR'...\n",
            "remote: Enumerating objects: 2753, done.\u001b[K\n",
            "remote: Counting objects: 100% (2/2), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 2753 (delta 0), reused 0 (delta 0), pack-reused 2751 (from 2)\u001b[K\n",
            "Receiving objects: 100% (2753/2753), 157.84 MiB | 21.51 MiB/s, done.\n",
            "Resolving deltas: 100% (1672/1672), done.\n",
            "Updating files: 100% (313/313), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/EasyOCR\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zsk8mYXyPBXh",
        "outputId": "8fd4f391-cff1-44aa-c46d-38168b424f35"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/EasyOCR\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class CRNN(nn.Module):\n",
        "    def __init__(self, nclass):\n",
        "        super().__init__()\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, 3, 1, 1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2,2),\n",
        "            nn.Conv2d(64, 128, 3, 1, 1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2,2)\n",
        "        )\n",
        "        self.rnn = nn.LSTM(128*8, 256, bidirectional=True, batch_first=True)\n",
        "        self.fc = nn.Linear(512, nclass)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.cnn(x)\n",
        "        b, c, h, w = x.size()\n",
        "        x = x.permute(0,3,1,2).contiguous()\n",
        "        x = x.view(b, w, c*h)\n",
        "        x,_ = self.rnn(x)\n",
        "        x = self.fc(x)\n",
        "        return x.log_softmax(2)\n"
      ],
      "metadata": {
        "id": "8fzBmH4kjwhM"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# -----------------------------\n",
        "# Alphabet\n",
        "# -----------------------------\n",
        "ALPHABET = \"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
        "char2idx = {c: i+1 for i, c in enumerate(ALPHABET)}\n",
        "\n",
        "# -----------------------------\n",
        "# Dataset\n",
        "# -----------------------------\n",
        "class OCRDataset(Dataset):\n",
        "    def __init__(self, root):\n",
        "        self.img_dir = os.path.join(root, \"images\")\n",
        "        self.samples = []\n",
        "\n",
        "        with open(os.path.join(root, \"labels.txt\")) as f:\n",
        "            for line in f:\n",
        "                name, text = line.strip().split(\"\\t\")\n",
        "                self.samples.append((name, text))\n",
        "\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.ToPILImage(),\n",
        "            transforms.Resize((32, 100)),\n",
        "            transforms.Grayscale(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5,), (0.5,))\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        name, text = self.samples[idx]\n",
        "        img = cv2.imread(os.path.join(self.img_dir, name))\n",
        "        img = self.transform(img)\n",
        "        target = torch.tensor([char2idx[c] for c in text], dtype=torch.long)\n",
        "        return img, target, len(target)\n",
        "\n",
        "def collate_fn(batch):\n",
        "    imgs, targets, lengths = zip(*batch)\n",
        "    imgs = torch.stack(imgs)\n",
        "    targets = torch.cat(targets)\n",
        "    lengths = torch.tensor(lengths)\n",
        "    return imgs, targets, lengths\n",
        "\n",
        "# -----------------------------\n",
        "# Model\n",
        "# -----------------------------\n",
        "class CRNN(nn.Module):\n",
        "    def __init__(self, nclass):\n",
        "        super().__init__()\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, 3, 1, 1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2,2),\n",
        "            nn.Conv2d(64, 128, 3, 1, 1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2,2)\n",
        "        )\n",
        "        self.rnn = nn.LSTM(128*8, 256, bidirectional=True, batch_first=True)\n",
        "        self.fc = nn.Linear(512, nclass)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.cnn(x)\n",
        "        b, c, h, w = x.size()\n",
        "        x = x.permute(0,3,1,2).contiguous()\n",
        "        x = x.view(b, w, c*h)\n",
        "        x,_ = self.rnn(x)\n",
        "        x = self.fc(x)\n",
        "        return x.log_softmax(2)\n",
        "\n",
        "# -----------------------------\n",
        "# Setup\n",
        "# -----------------------------\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "dataset = OCRDataset(\"/content/drive/MyDrive/ANPR_OCR_Dataset\")\n",
        "loader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "model = CRNN(len(ALPHABET) + 1).to(device)\n",
        "criterion = nn.CTCLoss(blank=0)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "print(\"Dataset size:\", len(dataset))\n",
        "print(\"Model initialized on:\", device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whPmhZYNPuUK",
        "outputId": "6d98ccfc-60e9-46e7-adc9-451efed698aa"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset size: 1337\n",
            "Model initialized on: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(5):\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i, (imgs, targets, lengths) in enumerate(loader):\n",
        "        if i % 20 == 0:\n",
        "            print(f\"Epoch {epoch+1} | Batch {i}/{len(loader)}\")\n",
        "\n",
        "        imgs = imgs.to(device)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        preds = model(imgs)\n",
        "        T = preds.size(1)\n",
        "\n",
        "        pred_lengths = torch.full(\n",
        "            (imgs.size(0),), T, dtype=torch.long\n",
        "        ).to(device)\n",
        "\n",
        "        loss = criterion(\n",
        "            preds.permute(1, 0, 2),\n",
        "            targets,\n",
        "            pred_lengths,\n",
        "            lengths\n",
        "        )\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(loader)\n",
        "    print(f\"Epoch {epoch+1} Loss: {avg_loss:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MGZrE9pxkE0C",
        "outputId": "0ab4dedb-b8af-4061-91e3-305cc8817313"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 | Batch 0/42\n",
            "Epoch 1 | Batch 20/42\n",
            "Epoch 1 | Batch 40/42\n",
            "Epoch 1 Loss: 3.2395\n",
            "Epoch 2 | Batch 0/42\n",
            "Epoch 2 | Batch 20/42\n",
            "Epoch 2 | Batch 40/42\n",
            "Epoch 2 Loss: 2.9739\n",
            "Epoch 3 | Batch 0/42\n",
            "Epoch 3 | Batch 20/42\n",
            "Epoch 3 | Batch 40/42\n",
            "Epoch 3 Loss: 2.8177\n",
            "Epoch 4 | Batch 0/42\n",
            "Epoch 4 | Batch 20/42\n",
            "Epoch 4 | Batch 40/42\n",
            "Epoch 4 Loss: 2.6642\n",
            "Epoch 5 | Batch 0/42\n",
            "Epoch 5 | Batch 20/42\n",
            "Epoch 5 | Batch 40/42\n",
            "Epoch 5 Loss: 2.5254\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(5, 20):\n",
        "    total_loss = 0.0\n",
        "    for imgs, targets, lengths in loader:\n",
        "        imgs = imgs.to(device)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        preds = model(imgs)\n",
        "        T = preds.size(1)\n",
        "        pred_lengths = torch.full(\n",
        "            (imgs.size(0),), T, dtype=torch.long\n",
        "        ).to(device)\n",
        "\n",
        "        loss = criterion(\n",
        "            preds.permute(1, 0, 2),\n",
        "            targets,\n",
        "            pred_lengths,\n",
        "            lengths\n",
        "        )\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1} Loss: {total_loss/len(loader):.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDJV_EiKhmRF",
        "outputId": "8455a39c-b1fe-49d0-cd49-555d9ca72413"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 Loss: 2.4225\n",
            "Epoch 7 Loss: 2.3222\n",
            "Epoch 8 Loss: 2.2016\n",
            "Epoch 9 Loss: 2.0136\n",
            "Epoch 10 Loss: 1.7705\n",
            "Epoch 11 Loss: 1.5401\n",
            "Epoch 12 Loss: 1.3602\n",
            "Epoch 13 Loss: 1.1942\n",
            "Epoch 14 Loss: 1.0454\n",
            "Epoch 15 Loss: 0.9116\n",
            "Epoch 16 Loss: 0.7917\n",
            "Epoch 17 Loss: 0.6753\n",
            "Epoch 18 Loss: 0.5740\n",
            "Epoch 19 Loss: 0.4739\n",
            "Epoch 20 Loss: 0.3932\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"/content/crnn_plate_ocr.pth\")\n",
        "print(\"Model saved\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHJjM6LroBQv",
        "outputId": "b30ea485-3239-4a70-d562-26c3ca9d4f20"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "MODEL_PATH = \"/content/crnn_plate_ocr.pth\"\n",
        "torch.save(model.state_dict(), MODEL_PATH)\n",
        "print(\"✅ Model saved at:\", MODEL_PATH)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2jpVLkdVK8e",
        "outputId": "6ccdbc91-f13b-46c4-d3b3-b8ddd3ed24b2"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model saved at: /content/crnn_plate_ocr.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ctc_greedy_decode(preds, idx2char):\n",
        "    \"\"\"\n",
        "    preds: (T, B, C) log-probabilities\n",
        "    \"\"\"\n",
        "    preds = preds.argmax(2)  # (T, B)\n",
        "    texts = []\n",
        "    for b in range(preds.size(1)):\n",
        "        prev = 0\n",
        "        text = \"\"\n",
        "        for t in preds[:, b]:\n",
        "            t = t.item()\n",
        "            if t != prev and t != 0:\n",
        "                text += idx2char[t]\n",
        "            prev = t\n",
        "        texts.append(text)\n",
        "    return texts\n"
      ],
      "metadata": {
        "id": "9Ay-YYv6Vxy9"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize((32, 100)),\n",
        "    transforms.Grayscale(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "def crnn_predict(image_bgr):\n",
        "    img = transform(image_bgr).unsqueeze(0).to(device)\n",
        "    with torch.no_grad():\n",
        "        out = model(img)                 # (B, T, C)\n",
        "        out = out.permute(1, 0, 2)        # (T, B, C)\n",
        "    return ctc_greedy_decode(out, idx2char)[0]\n",
        "\n",
        "# Try one image from your OCR dataset\n",
        "test_img_path = \"/content/drive/MyDrive/ANPR_OCR_Dataset/images/000020.jpg\"\n",
        "img = cv2.imread(test_img_path)\n",
        "print(\"Pred:\", crnn_predict(img))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXL-4qLGV1MV",
        "outputId": "83bc0a38-933c-434f-f241-a47bfb02d362"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pred: TR01N0481\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def cer(gt, pred):\n",
        "    # simple Levenshtein\n",
        "    import numpy as np\n",
        "    dp = np.zeros((len(gt)+1, len(pred)+1), dtype=int)\n",
        "    for i in range(len(gt)+1): dp[i][0] = i\n",
        "    for j in range(len(pred)+1): dp[0][j] = j\n",
        "    for i in range(1, len(gt)+1):\n",
        "        for j in range(1, len(pred)+1):\n",
        "            cost = 0 if gt[i-1] == pred[j-1] else 1\n",
        "            dp[i][j] = min(dp[i-1][j]+1, dp[i][j-1]+1, dp[i-1][j-1]+cost)\n",
        "    return dp[-1][-1] / max(1, len(gt))\n",
        "\n",
        "exact = 0\n",
        "cers = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for name, gt in dataset.samples:\n",
        "        img = cv2.imread(os.path.join(dataset.img_dir, name))\n",
        "        pred = crnn_predict(img)\n",
        "        if pred == gt:\n",
        "            exact += 1\n",
        "        cers.append(cer(gt, pred))\n",
        "\n",
        "print(\"Exact Match:\", exact / len(dataset))\n",
        "print(\"Mean CER   :\", np.mean(cers))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHx1Z_q4V4o9",
        "outputId": "0324dd01-13b5-49ce-aa3c-ef4488868449"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exact Match: 0.6379955123410621\n",
            "Mean CER   : 0.05572714910785217\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dzeIXMWNWI02"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}